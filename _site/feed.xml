<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>THETA 360 Unofficial Blog</title>
    <description>Community information for developers of applications for the RICOH THETA camera. Go to theta360.guide for more information.
</description>
    <link>http://theta360.guide/blog/</link>
    <atom:link href="http://theta360.guide/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 30 Nov 2016 01:09:34 +0000</pubDate>
    <lastBuildDate>Wed, 30 Nov 2016 01:09:34 +0000</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>Guide to Using THETA Images With Unity Background Skybox Pt 1</title>
        <description>&lt;p&gt;In order to help developers use THETA images in their projects, Jesse Casman and I have been working on a demonstration of THETA images in Unity Skybox. This &lt;a href=&quot;https://youtu.be/c-MoLjcYmi8&quot;&gt;video tutorial covers the steps&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We’ve prepared four scenes. Each scene only takes a few minutes to build. It would be better if @jcasman had supplied me with images of scenery without people. It’s better if the scene is taken outside. For example night sky, mountain view, canyon, agricultural field, city landscape.&lt;/p&gt;

&lt;p&gt;This is the original scene taken outdoor in front of a museum by my daughter.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://lists.theta360.guide/uploads/default/original/2X/b/b4cbbdb49621f51d6b195a7f3ed5b7ac7ad6bc40.png&quot; width=&quot;690&quot; height=&quot;374&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;This is a scene of San Francisco in front of the Oppkey global headquarters. Is that right, @jcasman?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://lists.theta360.guide/uploads/default/original/2X/d/d1f8e59e3f03efc95b2c86fe103f808a498658f6.png&quot; width=&quot;690&quot; height=&quot;374&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;This is a scene taken from a museum.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://lists.theta360.guide/uploads/default/original/2X/c/c71b4454a565598b759ca0638fcd94455a4e5766.png&quot; width=&quot;690&quot; height=&quot;374&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;This is scene taken at a bar where one of the staff looks like a giant.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://lists.theta360.guide/uploads/default/original/2X/f/f5729a5fe734fabd2954ef0256bb09d3072d9e80.png&quot; width=&quot;690&quot; height=&quot;374&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Unity is free. You can download it from &lt;a href=&quot;https://unity3d.com/get-unity/download&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The Unity project file is &lt;a href=&quot;https://drive.google.com/file/d/0B3V9jzGQTmyBS3FjTHo3Q2V1Q28/view?usp=sharing&quot;&gt;here&lt;/a&gt;. (151MB download)&lt;/p&gt;
</description>
        <pubDate>Tue, 29 Nov 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/unity/2016/11/29/guide-to-theta-unity-skybox.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/unity/2016/11/29/guide-to-theta-unity-skybox.html</guid>
        
        
        <category>Unity</category>
        
      </item>
    
      <item>
        <title>Augmented Reality Image Example</title>
        <description>&lt;p&gt;Using the video tutorial on &lt;a href=&quot;https://www.youtube.com/watch?v=c-MoLjcYmi8&quot;&gt;using 360 images in Unity for augmented reality&lt;/a&gt;
and &lt;a href=&quot;http://theta360.guide/blog/unity/2016/10/22/tutorial-unity-360-image-sphere.html&quot;&gt;blog post&lt;/a&gt;, you can use 360
images as a background to your augmented reality project.&lt;/p&gt;

&lt;p&gt;To illustrate the ease of creating Unity projects, I took my pre-teen daughter to
Stanford University Cantor Arts Center and asked her to take pictures with a THETA
S.&lt;/p&gt;

&lt;p&gt;Back at home, I showed her how to import 3D assets into her 360 photo scenes.&lt;/p&gt;

&lt;p&gt;Starting with a THETA image of rocks, she dropped it into the background
and added free 3D assets from &lt;a href=&quot;http://archive3d.net/&quot;&gt;Archive3D&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This is the original image.
&lt;img src=&quot;/blog/img/2016-10/unity/ar/rocks.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These are screenshots from the 3D scene she created.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/ar/girl-cat.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/ar/cat-door.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/ar/girl-window.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Outside of the museum, she took a picture of a field.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/ar/field.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;At home, she added additional 3D assets.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/ar/swan.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/ar/dog.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/unity/2016/10/23/augmented-reality-image-example.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/unity/2016/10/23/augmented-reality-image-example.html</guid>
        
        
        <category>Unity</category>
        
      </item>
    
      <item>
        <title>Beginner Tutorial: RICOH THETA 360 Images in Unity</title>
        <description>&lt;p&gt;There’s a new video tutorial on &lt;a href=&quot;https://www.youtube.com/watch?v=c-MoLjcYmi8&quot;&gt;using 360 images in Unity for augmented reality&lt;/a&gt;&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/c-MoLjcYmi8&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Unity can be used to quickly create 3D worlds for augmented reality
 games and other experiences such as tours.&lt;/p&gt;

&lt;p&gt;The editor allows 3D objects to be placed on the screen with a mouse.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/skybox/scene-background.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Images can be converted into cubemaps for placement inside of a 3D world as the
background.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/skybox/cubemap-view.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once in the world, the image view can be navigated.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/skybox/up-view.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The application can be saved as a binary and run natively on Windows, Mac, and
Linux.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/skybox/windows-icon.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The application can run in full-screen or windowed mode. You can use the
mouse, arrow or WASD to walk or run around the environment.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/skybox/native-windowed.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can also run the application in a web browser such as Firefox or Chrome.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/skybox/browser.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;watch-the-video-nowhttpswwwyoutubecomwatchvc-moljcymi8&quot;&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=c-MoLjcYmi8&quot;&gt;Watch The Video Now&lt;/a&gt;&lt;/h1&gt;
</description>
        <pubDate>Sat, 22 Oct 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/unity/2016/10/22/tutorial-unity-360-image-sphere.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/unity/2016/10/22/tutorial-unity-360-image-sphere.html</guid>
        
        
        <category>Unity</category>
        
      </item>
    
      <item>
        <title>RICOH THETA 360 Video (From File) Unity Tutorial</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=fiucH5q_4VE&quot;&gt;&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/video-tutorial.png&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=fiucH5q_4VE&quot;&gt;Video tutorial&lt;/a&gt; available.&lt;/p&gt;

&lt;h2 id=&quot;prepare-theta-videos-in-equirectangular-format&quot;&gt;Prepare THETA Videos in Equirectangular Format&lt;/h2&gt;
&lt;p&gt;Use the official THETA desktop application to convert the dual-fisheye
video into equirectangular.
&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/video-convert.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;create-new-unity-project&quot;&gt;Create New Unity Project&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/unity-new-project.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Save Scene as 360video&lt;/li&gt;
  &lt;li&gt;Position Main Camera in center at 0, 0, 0&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;create-sphere&quot;&gt;Create Sphere&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/sphere.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Position at 0, 0, 0&lt;/li&gt;
  &lt;li&gt;Scale Sphere to 10, 10, 10&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;create-materials&quot;&gt;Create Materials&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Create new folder called &lt;em&gt;Materials&lt;/em&gt; under &lt;em&gt;Assets&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;In &lt;em&gt;Materials&lt;/em&gt; create material called 360Video&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;add-material-to-sphere&quot;&gt;Add Material to Sphere&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/add-material-sphere.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;create-shader&quot;&gt;Create Shader&lt;/h2&gt;
&lt;p&gt;In &lt;em&gt;Assets&lt;/em&gt; create new folder, &lt;em&gt;Shaders&lt;/em&gt;. Create new Unlit Shader in the folder.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/unlit-shader.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Rename shader. I called mine, &lt;em&gt;ViewInside&lt;/em&gt; Double-click on the new Shader.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/shader-icon.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Drop in the code below from community member &lt;a href=&quot;http://tengshanyuan.com/&quot;&gt;Shanyuan Teng&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Shader &quot;ThetaInsideShader&quot; {
	Properties{
		_MainTex(&quot;Base (RGB)&quot;, 2D) = &quot;white&quot; {}
	}

		SubShader{
		Tags{ &quot;RenderType&quot; = &quot;Opaque&quot; }
		Cull front    //  FLIP THE SURFACES
		LOD 100

		Pass{
		CGPROGRAM
#pragma vertex vert
#pragma fragment frag

#include &quot;UnityCG.cginc&quot;

		struct appdata_t {
		float4 vertex : POSITION;
		float2 texcoord : TEXCOORD0;
	};

	struct v2f {
		float4 vertex : SV_POSITION;
		half2 texcoord : TEXCOORD0;
	};

	sampler2D _MainTex;
	float4 _MainTex_ST;

	v2f vert(appdata_t v)
	{
		v2f o;
		o.vertex = mul(UNITY_MATRIX_MVP, v.vertex);
		v.texcoord.x = 1 - v.texcoord.x;
		o.texcoord = TRANSFORM_TEX(v.texcoord, _MainTex);
		return o;
	}

	fixed4 frag(v2f i) : SV_Target
	{
		fixed4 col = tex2D(_MainTex, i.texcoord);
	return col;
	}
		ENDCG
	}
	}

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;add-shader-to-sphere&quot;&gt;Add Shader to Sphere&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/shader-sphere.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;add-360-video-asset&quot;&gt;Add 360 Video Asset&lt;/h2&gt;

&lt;p&gt;In &lt;em&gt;Assets&lt;/em&gt;, create a new folder &lt;em&gt;Videos&lt;/em&gt;. Drop you THETA equirectangular video
into the folder. Any resolution is fine.  Import may take several minutes.
If you’re on Windows, Unity needs QuickTime for the import.&lt;/p&gt;

&lt;h2 id=&quot;create-empty-game-object&quot;&gt;Create Empty Game Object&lt;/h2&gt;
&lt;p&gt;I called mine &lt;em&gt;VideoPlayback&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;add-playback-script&quot;&gt;Add Playback Script&lt;/h2&gt;
&lt;p&gt;Connect a video playback script to the new game object, &lt;em&gt;VideoPlayback&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This is the code from community member &lt;a href=&quot;http://tengshanyuan.com/&quot;&gt;Shanyuan Teng&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;using UnityEngine;
using System.Collections;

public class VideoPlayback : MonoBehaviour {

    public GameObject Sphere;

	// Use this for initialization
	void Start () {

        MovieTexture video360 = (MovieTexture)Sphere.GetComponent&amp;lt;Renderer&amp;gt;().material.mainTexture;
        video360.loop = true;
        video360.Play();
	}

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;add-texture-to-video-sphere&quot;&gt;Add Texture to Video Sphere&lt;/h2&gt;

&lt;p&gt;Drop your video onto the texture box in 360Video. Your video file is the
texture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/video-texture.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;play-it&quot;&gt;Play It!&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity-tutorial/play-video.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Oct 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/video,/unity/2016/10/16/video-file-on-unity-sphere.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/video,/unity/2016/10/16/video-file-on-unity-sphere.html</guid>
        
        
        <category>Video,</category>
        
        <category>Unity</category>
        
      </item>
    
      <item>
        <title>First Impression of Unity for THETA Live Streaming</title>
        <description>&lt;p&gt;I spent last night in Santa Cruz and was planning to go surfing this morning,
but when I woke up, I saw that red tide had hit the coast and was I decided
to stay on shore, install Unity on my laptop and get Makoto-san’s
&lt;a href=&quot;https://github.com/theta360developers/ThetaWifiStreaming&quot;&gt;ThetaWifiStreaming&lt;/a&gt;
app working.&lt;/p&gt;

&lt;p&gt;Wow. I simply opened up the project in Unity, pressed &lt;em&gt;Play&lt;/em&gt;, and the WiFi
360 streaming started to work.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/game-view-crop.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Going to the &lt;em&gt;Scene&lt;/em&gt; tab, I was able to change the perspective.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/scene-1-crop.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using the scroll wheel, I was able to zoom out on the sphere to see exterior
of the 360 video.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/scene-2-crop.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Usually, when you watch a 360 video on YouTube, your perspective
is from the center of the sphere. It’s cool to see the outside. It’s so
cool that I zoomed out more and realized I could put the sphere on a plane.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/scene-4-crop.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I adjusted the Scene view to get a top-down perspective of the video sphere
and see the stitching.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/scene-3-crop.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I then oriented the camera to face me directly to get a better view of the
stitching.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity/top-down-sphere.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The stitching to equirectangular MotionJPEG is done inside of the THETA using
RICOH’s proprietary ASIC chip. As you would expect, the stitching is great.
The main downside is that the video stream
is only 640x320 and streams over WiFi at 10fps.&lt;/p&gt;

&lt;p&gt;In a
&lt;a href=&quot;http://theta360.guide/blog/live/streaming/2016/10/14/wifi-streaming-theta-s-unity.html&quot;&gt;previous blog post&lt;/a&gt;, I showed a picture from Makoto-san of his app working
on a mobile phone.&lt;/p&gt;

&lt;p&gt;The streaming is intended only to preview still images. However, it’s fun to
play with and get a taste for what might be possible in the future with 360
video streams.&lt;/p&gt;
</description>
        <pubDate>Sat, 15 Oct 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/live/streaming/2016/10/15/unity-first-experience.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/live/streaming/2016/10/15/unity-first-experience.html</guid>
        
        
        <category>Live</category>
        
        <category>Streaming</category>
        
      </item>
    
      <item>
        <title>WiFi Streaming THETA S in Unity</title>
        <description>&lt;p&gt;This article was originally written by &lt;a href=&quot;https://twitter.com/noshipu&quot;&gt;@noshipu&lt;/a&gt;,
CEO of &lt;a href=&quot;http://vird.co.jp/&quot;&gt;ViRD, Inc&lt;/a&gt; in Japanese. It was translated into English
at the request of the THETA developer community in the US. All credit to this great
article goes to Noshipu-san.&lt;/p&gt;

&lt;p&gt;Makoto-san produced a finished app.
Code is &lt;a href=&quot;https://github.com/theta360developers/ThetaWifiStreaming&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity-middle.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/unity2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;about-the-ricoh-theta-api&quot;&gt;About the RICOH THETA API&lt;/h1&gt;

&lt;p&gt;In order to use Wifi live streaming, you must use the &lt;code class=&quot;highlighter-rouge&quot;&gt;_getLivePreview&lt;/code&gt; API.
&lt;a href=&quot;https://developers.theta360.com/en/docs/v2.0/api_reference/commands/camera._get_live_preview.html&quot;&gt;Official Reference&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NOTE from Craig: This was replaced by &lt;a href=&quot;https://developers.theta360.com/en/docs/v2.1/api_reference/commands/camera.get_live_preview.html&quot;&gt;getLivePreview&lt;/a&gt; in version 2.1 of the API. This blog by Noshipu-san refers to the 2.0 API, which is still supported by
the THETA S. Be aware of the differences in your code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Unlike the other APIs, &lt;code class=&quot;highlighter-rouge&quot;&gt;_getLivePreview&lt;/code&gt; is different because the data is in a stream and keeps going. You will not be able to get a WWW class to wait until the request is complete (maybe).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NOTE from Craig: This is the major problem developers have when working with &lt;code class=&quot;highlighter-rouge&quot;&gt;getLivePreview&lt;/code&gt;. As the data
is a stream, you can’t want for the data to end before running your next command. For example, it’s
different from downloading and displaying an image or video file because you know when the transfer is
complete.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;processing-flow&quot;&gt;Processing Flow&lt;/h1&gt;

&lt;h2 id=&quot;set-the-post-request-to-create-a-httpwebrequest-class&quot;&gt;Set the POST request to create a HttpWebRequest class&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;string url = &quot;Enter HTTP path of THETA here&quot;;
var request = HttpWebRequest.Create (url);
HttpWebResponse response = null;
request.Method = &quot;POST&quot;;
request.Timeout = (int) (30 * 10000f); // to ensure  no timeout
request.ContentType = &quot;application/json; charset = utf-8&quot;;

byte [] postBytes = Encoding.Default.GetBytes ( &quot;Put the JSON data here&quot;);
request.ContentLength = postBytes.Length;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;generate-a-class-of-binaryreader-to-get-the-byte-data-you-get-the-bytes-one-by-one&quot;&gt;Generate a class of BinaryReader to get the byte data (you get the bytes one by one)&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// The start of transmission of the post data
Stream reqStream = request.GetRequestStream ();
reqStream.Write (postBytes, 0, postBytes.Length) ;
reqStream.Close ();
stream = request.GetResponse () .GetResponseStream ();

BinaryReader reader = new BinaryReader (new BufferedStream (stream), new System.Text.ASCIIEncoding ());
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;get-the-start-and-stop-bytes-of-1-frame-of-the-motionjpeg-and-cut-out-one-frame&quot;&gt;Get the start and stop bytes of 1 frame of the MotionJPEG and cut out one frame&lt;/h2&gt;

&lt;p&gt;With the byte, check the partion value of the MotionJPEG.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...(http)
0xFF 0xD8      --|
[jpeg data]      |--1 frame of MotionJPEG
0xFF 0xD9      --|
...(http)
0xFF 0xD8      --|
[jpeg data]      |--1 frame of MotionJPEG
0xFF 0xD9      --|
...(http)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Please refer this answer on StackOverflow to
&lt;a href=&quot;http://stackoverflow.com/questions/21702477/how-to-parse-mjpeg-http-stream-from-ip-camera&quot;&gt;How to Parse MJPEG HTTP stream from IP camera?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The starting 2 bytes are &lt;code class=&quot;highlighter-rouge&quot;&gt;0xFF, 0xD8&lt;/code&gt;. The end bye is &lt;code class=&quot;highlighter-rouge&quot;&gt;0xD9&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The code is shown below.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;List&amp;lt;byte&amp;gt; imageBytes = new List&amp;lt;byte&amp;gt; ();
bool isLoadStart = false; // 画像の頭のバイナリとったかフラグ
byte oldByte = 0; // 1つ前のByteデータを格納する
while( true ) {
    byte byteData = reader.ReadByte ();

    if (!isLoadStart) {
        if (oldByte == 0xFF){
            // First binary image
           imageBytes.Add(0xFF);
        }
        if (byteData == 0xD8){
           // Second binary image
           imageBytes.Add(0xD8);

           // I took the head of the image up to the end binary
           isLoadStart = true;
        }
    } else {
        // Put the image binaries into an array
        imageBytes.Add(byteData);

        // if the byte was the end byte
        // 0xFF -&amp;gt; 0xD9 case、end byte
        if(oldByte == 0xFF &amp;amp;&amp;amp; byteData == 0xD9){
            // As this is the end byte
            // we&#39;ll generate the image from the data and can create the texture
            // imageBytes are used to reflect the texture
            // imageBytes are left empty
            // the loop returns the binary image head
            isLoadStart = false;
        }
    }
    oldByte = byteData;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;texture-generation-separated-by-byte&quot;&gt;Texture Generation Separated by Byte&lt;/h2&gt;

&lt;p&gt;This is the byte to reflect the texture.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mainTexture.LoadImage ((byte[])imageBytes.ToArray ());
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;Portion of Python code taken from &lt;a href=&quot;http://stackoverflow.com/questions/21702477/how-to-parse-mjpeg-http-stream-from-ip-camera&quot;&gt;StackOverflow answer&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import cv2
import urllib
import numpy as np

stream=urllib.urlopen(&#39;http://localhost:8080/frame.mjpg&#39;)
bytes=&#39;&#39;
while True:
    bytes+=stream.read(1024)
    a = bytes.find(&#39;\xff\xd8&#39;)
    b = bytes.find(&#39;\xff\xd9&#39;)
    if a!=-1 and b!=-1:
        jpg = bytes[a:b+2]
        bytes= bytes[b+2:]
        i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8),cv2.CV_LOAD_IMAGE_COLOR)
        cv2.imshow(&#39;i&#39;,i)
        if cv2.waitKey(1) ==27:
            exit(0) Mjpeg over http is multipart/x-mixed-replace with boundary frame info and jpeg data is just sent in binary. So you don&#39;t really need to care about http protocol headers. All jpeg frames start with marker 0xff 0xd8 and end with 0xff 0xd9. So the code above extracts such frames from the http stream and decodes them one by one. like below.

...(http)
0xff 0xd8      --|
[jpeg data]      |--this part is extracted and decoded
0xff 0xd9      --|
...(http)
0xff 0xd8      --|
[jpeg data]      |--this part is extracted and decoded
0xff 0xd9      --|
...(http)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 14 Oct 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/live/streaming/2016/10/14/wifi-streaming-theta-s-unity.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/live/streaming/2016/10/14/wifi-streaming-theta-s-unity.html</guid>
        
        
        <category>Live</category>
        
        <category>Streaming</category>
        
      </item>
    
      <item>
        <title>RICOH THETA Button Quick Reference</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/button-guide.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Live Streaming: Press and hold mode. While continuing to hold mode, press power.&lt;/li&gt;
  &lt;li&gt;Mass Storage: Press Wireless and Shutter. While continuing to hold these buttons,
plug THETA into computer with USB cable. Camera will be powered off.&lt;/li&gt;
  &lt;li&gt;Self-Timer: Press and hold wireless. While continuing to hold wireless, press power.
LED will be green.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;troubleshooting&quot;&gt;Troubleshooting&lt;/h2&gt;

&lt;p&gt;Mass storage doesn’t work. Press and hold the power button for longer than
8 seconds to reset camera, then press power button again. If using a Mac,
try a different USB port.&lt;/p&gt;

&lt;h1 id=&quot;discusshttpliststheta360guidetricoh-theta-button-quick-reference478ucodetricity&quot;&gt;&lt;a href=&quot;http://lists.theta360.guide/t/ricoh-theta-button-quick-reference/478?u=codetricity&quot;&gt;Discuss&lt;/a&gt;&lt;/h1&gt;
</description>
        <pubDate>Fri, 07 Oct 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/camera/2016/10/07/ricoh-theta-button-quick-reference.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/camera/2016/10/07/ricoh-theta-button-quick-reference.html</guid>
        
        
        <category>Camera</category>
        
      </item>
    
      <item>
        <title>Easily Create a 360 Gallery For RICOH THETA with A-Frame</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://codetricity.github.io/360gallery/&quot;&gt;&lt;img src=&quot;http://lists.theta360.guide/uploads/default/original/1X/d11f4be895176ddeaa99851f66c8e2868c4adcc7.jpg&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Using the open source &lt;a href=&quot;https://aframe.io/docs/0.3.0/introduction/&quot;&gt;A-Frame&lt;/a&gt;
JavaScript library, you can
&lt;a href=&quot;http://theta360.guide/blog/webvr/2016/09/14/using-aframe-ricoh-theta.html&quot;&gt;write a few lines of code&lt;/a&gt;
 and get THETA 360 images
 &lt;a href=&quot;https://codetricity.github.io/aframe-demo/scene1.html&quot;&gt;working&lt;/a&gt;
  in a headset or Cardboard with
navigation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/aframe-navigation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Headset navigation works by displaying a round cursor inside the headset view
that corresponds to the focus of your attention. If you turn the headset so that the
cursor is on a menu, you will jump to another sphere. In actual use, it feels natural. You
just stare at a menu for a second and then the jump occurs. The delay for the stare is
configurable within your code.&lt;/p&gt;

&lt;p&gt;In this example, the menus are stuck to a location in the sphere.
Moving your head causes the menus to move.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/aframe-menu-movement.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;creating-menus&quot;&gt;Creating Menus&lt;/h1&gt;

&lt;h2 id=&quot;download-boilerplate-code-from-github&quot;&gt;Download Boilerplate Code from GitHub&lt;/h2&gt;
&lt;p&gt;Fork the &lt;a href=&quot;https://github.com/theta360developers/360gallery&quot;&gt;demo on GitHub&lt;/a&gt;
and clone to your local drive.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/aframe-files.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Drop your 360 images from the THETA into &lt;code class=&quot;highlighter-rouge&quot;&gt;img/&lt;/code&gt;.
Open &lt;code class=&quot;highlighter-rouge&quot;&gt;index.html&lt;/code&gt; in your editor.&lt;/p&gt;

&lt;h2 id=&quot;create-thumbnail-images&quot;&gt;Create Thumbnail Images&lt;/h2&gt;

&lt;p&gt;Using an image editor like PhotoShop create thumbnail images that are
240x240 pixels. For this example, I’m using bitmap image text menus.
You can also
drop in small images as the navigational menu.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/image-files.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;edit-file-names-and-id-links&quot;&gt;Edit File Names and ID Links&lt;/h2&gt;
&lt;p&gt;In your editor, change the &lt;code class=&quot;highlighter-rouge&quot;&gt;id&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;src&lt;/code&gt; to match your files. If you
are new to programming, simply overwrite &lt;code class=&quot;highlighter-rouge&quot;&gt;1.jpg&lt;/code&gt; in your &lt;code class=&quot;highlighter-rouge&quot;&gt;/img&lt;/code&gt; folder
with your own image file first for testing. If you use the same image file
names, you do not need to edit the code at all.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/edit-files.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;body&amp;gt;
  &amp;lt;a-scene&amp;gt;
    &amp;lt;a-assets&amp;gt;
      &amp;lt;img id=&quot;kieran&quot; src=&quot;img/1.jpg&quot;&amp;gt;
      &amp;lt;img id=&quot;kieran-thumb&quot; crossorigin=&quot;anonymous&quot; src=&quot;img/kieran-thumb.png&quot;&amp;gt;
      &amp;lt;img id=&quot;christian-thumb&quot; crossorigin=&quot;anonymous&quot; src=&quot;img/christian-thumb.png&quot;&amp;gt;
      &amp;lt;img id=&quot;eddie-thumb&quot; crossorigin=&quot;anonymous&quot; src=&quot;img/eddie-thumb.png&quot;&amp;gt;
      &amp;lt;audio id=&quot;click-sound&quot; crossorigin=&quot;anonymous&quot; src=&quot;https://cdn.aframe.io/360-image-gallery-boilerplate/audio/click.ogg&quot;&amp;gt;&amp;lt;/audio&amp;gt;
      &amp;lt;img id=&quot;christian&quot; crossorigin=&quot;anonymous&quot; src=&quot;img/2.jpg&quot;&amp;gt;
      &amp;lt;img id=&quot;eddie&quot; crossorigin=&quot;anonymous&quot; src=&quot;img/4.jpg&quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Assuming you are changing the file names, then edit the code for the
menu links.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/edit-file-menu.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;!-- 360-degree image. --&amp;gt;
&amp;lt;a-sky id=&quot;image-360&quot; radius=&quot;10&quot; src=&quot;#kieran&quot;&amp;gt;&amp;lt;/a-sky&amp;gt;

&amp;lt;!-- Image links. --&amp;gt;
&amp;lt;a-entity id=&quot;links&quot; layout=&quot;type: line; margin: 1.5&quot; position=&quot;0 -1 -4&quot;&amp;gt;
  &amp;lt;a-entity template=&quot;src: #link&quot; data-src=&quot;#christian&quot; data-thumb=&quot;#christian-thumb&quot;&amp;gt;&amp;lt;/a-entity&amp;gt;
  &amp;lt;a-entity template=&quot;src: #link&quot; data-src=&quot;#kieran&quot; data-thumb=&quot;#kieran-thumb&quot;&amp;gt;&amp;lt;/a-entity&amp;gt;
  &amp;lt;a-entity template=&quot;src: #link&quot; data-src=&quot;#eddie&quot; data-thumb=&quot;#eddie-thumb&quot;&amp;gt;&amp;lt;/a-entity&amp;gt;
&amp;lt;/a-entity&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;push-to-github-pages&quot;&gt;Push to GitHub Pages&lt;/h2&gt;
&lt;p&gt;That’s it. Add all your files to your local git repo, commit, and push to your forked repo, gh-pages branch.&lt;/p&gt;

&lt;p&gt;You should then be able to view your app at username.github.io/360gallery/&lt;/p&gt;

&lt;h2 id=&quot;running-an-http-server-locally-for-testing&quot;&gt;Running an HTTP Server Locally for Testing&lt;/h2&gt;

&lt;p&gt;You won’t be able to open the &lt;code class=&quot;highlighter-rouge&quot;&gt;index.html&lt;/code&gt; file locally for testing due to
CORS security. For testing, I’m running the Apache2 web server on Ubuntu 16.04
in Vagrant. I’m running Vagrant on Windows 10 Anniversary Edition. I then use
Firefox or Chrome running on my Windows 10 host to view the 360 images in the
Linux VM. I’m editing the files using Atom running natively on Windows 10. The
files are inside of the Linux VM, but I can access them from Windows. The end
result is that I can access http:localhost:8080/gallery and test my
application locally.&lt;/p&gt;

&lt;p&gt;If this sounds like too much hassle, just load the files up to GitHub Pages.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-10/localbrowser.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://theta360.guide/blog/webvr/2016/09/14/using-aframe-ricoh-theta.html&quot;&gt;Easier Intro to WebVR&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aframe.io/&quot;&gt;A-Frame&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://webvr.info/&quot;&gt;WebVR&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mozvr.com/&quot;&gt;MozVR&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://lists.theta360.guide/&quot;&gt;RICOH THETA Community Forum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;discusshttpliststheta360guideteasily-create-a-360-gallery-for-ricoh-theta-with-a-frame456&quot;&gt;&lt;a href=&quot;http://lists.theta360.guide/t/easily-create-a-360-gallery-for-ricoh-theta-with-a-frame/456&quot;&gt;Discuss&lt;/a&gt;&lt;/h1&gt;
</description>
        <pubDate>Tue, 04 Oct 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/webvr/2016/10/04/360-gallery-aframe-theta.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/webvr/2016/10/04/360-gallery-aframe-theta.html</guid>
        
        
        <category>WebVR</category>
        
      </item>
    
      <item>
        <title>RICOH THETA and WebVR - Quick HowTo</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/img/2016-09/aframe-mobile.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The future of virtual reality and augmented reality is &lt;a href=&quot;http://venturebeat.com/2016/09/17/how-webvr-will-make-virtual-reality-massively-available/&quot;&gt;WebVR&lt;/a&gt;.
It’s open source JavaScript, works with browsers and mobile phones today.
THETA media works great with it. Support for Occulus Rift and HTC Vive
headsets is available today in development builds and will be available
to the general public by the end of 2016.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-09/occulus-rift.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It’s easy to get started and powerful enough to build amazing applications.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-09/web-vr-menu.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Let’s get started with a simple THETA VR site using
&lt;a href=&quot;https://aframe.io/&quot;&gt;A-Frame&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Using your mobile phone, go to this sample link:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://codetricity.github.io/aframe-demo/scene1.html&quot;&gt;https://codetricity.github.io/aframe-demo/scene1.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Put the mobile phone in Cardboard and you’ll be able to navigate the image by moving your phone.&lt;/p&gt;

&lt;p&gt;The image will look like this. Press the goggle icon to split the image.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-09/meetup-image.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There’s nothing unusual here except that the main code is one line.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-09/code-sample.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/theta360developers/aframe-demo&quot;&gt;Fork the sample code&lt;/a&gt; on GitHub.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-09/github.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Copy your THETA pictures into the image sub-directory.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-09/image-directory.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Open the file &lt;code class=&quot;highlighter-rouge&quot;&gt;scene1.html&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;html&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;head&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;meta&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;charset=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;title&amp;gt;&lt;/span&gt;RICOH THETA MeetUp Test Scene 1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/title&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;meta&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;description&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;content=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Panorama — A-Frame&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dist/aframe.js&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;a-scene&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;a-sky&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;image/1.jpg&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rotation=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0 -130 0&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/a-sky&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/a-scene&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Change &lt;code class=&quot;highlighter-rouge&quot;&gt;src/1.jpg&lt;/code&gt; to the name of your file.&lt;/p&gt;

&lt;p&gt;Push the file back up to GitHub Pages and view the URL in your browser. That’s
it. You can now refer to the &lt;a href=&quot;https://aframe.io/&quot;&gt;A-Frame&lt;/a&gt;
site to come up with ideas to build
your interface.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;troubleshooting&quot;&gt;Troubleshooting&lt;/h2&gt;

&lt;p&gt;If you open the file on your local computer without uploading to
GitHub Pages, you may see this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/2016-09/console-error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The error message in your JavaScript console will be:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Image from origin ‘file://’ has been blocked from loading by Cross-Origin
Resource Sharing policy: Invalid response.
Origin ‘null’ is therefore not allowed access.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The fastest way to sort this out is to simply to push to gh-pages.
I’m assuming that you’re familiar with gh-pages or can figure it out
with a quick web search. The super short version: &lt;code class=&quot;highlighter-rouge&quot;&gt;git add *&lt;/code&gt;, which will
add all your files &lt;code class=&quot;highlighter-rouge&quot;&gt;git commit -a&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;git push&lt;/code&gt;. Make sure you push to
the &lt;code class=&quot;highlighter-rouge&quot;&gt;gh-pages&lt;/code&gt; branch. Your site will be up at
username.github.io/aframe-demo/scene1.html&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;chrome://flags&lt;/code&gt;
&lt;img src=&quot;/blog/img/2016-09/chrome-flags.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://aframe.io/&quot;&gt;A-Frame&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://webvr.info/&quot;&gt;WebVR&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mozvr.com/&quot;&gt;MozVR&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://lists.theta360.guide/&quot;&gt;RICOH THETA Community Forum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Part 2 -
&lt;a href=&quot;http://theta360.guide/blog/webvr/2016/10/04/360-gallery-aframe-theta.html&quot;&gt;Easily Create a 360 Gallery For RICOH THETA with A-Frame&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;discusshttpliststheta360guidetricoh-theta-and-webvr-quick-howto440ucodetricity&quot;&gt;&lt;a href=&quot;http://lists.theta360.guide/t/ricoh-theta-and-webvr-quick-howto/440?u=codetricity&quot;&gt;Discuss&lt;/a&gt;&lt;/h2&gt;
</description>
        <pubDate>Wed, 14 Sep 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/webvr/2016/09/14/using-aframe-ricoh-theta.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/webvr/2016/09/14/using-aframe-ricoh-theta.html</guid>
        
        
        <category>WebVR</category>
        
      </item>
    
      <item>
        <title>Sept 27 RICOH THETA Meetup in SF</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://www.meetup.com/RICOH-THETA-Developers-SF-Bay-Area/events/233546861/&quot;&gt;Sign up&lt;/a&gt; for the meetup!&lt;/p&gt;

&lt;h2 id=&quot;integration-in-products-photosphere-navigation-and-360-video-on-drones&quot;&gt;360° Integration in Products, Photosphere Navigation, and 360° Video on Drones!&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;RICOH THETA Developers Meetup&lt;/strong&gt;
&lt;strong&gt;Tues, Sept 27, 2016&lt;/strong&gt;
&lt;strong&gt;Location: San Francisco SOMA (TBD)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Wow, we’ve got a great lineup of presenters to kick off the fall schedule of RICOH THETA meetups! Come join your fellow power users and 360 developers and find out more about integrating 360 video/VR/AR into products. Then spend some time thinking how you can navigate and connect photosphere content. And finally, who doesn’t want to stick a THETA on a drone? We’ll do it this coming Tues, Sept 27th.&lt;/p&gt;

&lt;p&gt;Come ask your questions and share your own experiences in a friendly, relaxed environment. Whether you’re new to RICOH THETA, working on a project, or just want to meet people with similar interests, all are welcome.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Agenda&lt;/strong&gt;
6:30 pm: Check-in, grab pizza and sodas, and say hi to other RICOH THETA users and developers
7:00 pm: First talk: How to Integrate 360 Video/VR/AR Into Your Product, Kieran Farr, Brightcove
7:45 pm: Break
8:00 pm: Second talk: Better 360 Image Navigation Online, Christian Claus, Holobuilder
8:30 pm: Break
8:45 pm: Third talk and demo: RICOH THETA and Drones, Eddie Codel, eddie.com&lt;/p&gt;

&lt;p&gt;Speakers:
&lt;strong&gt;Kieran Farr&lt;/strong&gt; - Senior Director, Business Development, Brightcove (kfarr@brightcove.com)&lt;/p&gt;

&lt;h2 id=&quot;how-to-integrate-360-videovrar-into-your-product&quot;&gt;&lt;strong&gt;How to Integrate 360 Video/VR/AR Into Your Product&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://lists.theta360.guide/uploads/default/original/1X/b2b43836c722dc8c2ca1023de043bb236f79d9d6.png&quot; width=&quot;170&quot; height=&quot;170&quot; /&gt;
Kieran has a long background in video platform development running companies like Vidlet and Vidcaster, and now overseeing ecosystem and partner program development at Brightcove. Let his pain be your gain! He will dive into the nuts and bolts of how to stream 360º video standalone or as part of a larger product. Topics include: how to plan for and build the infrastructure, tying in a database, integrating with a CDN and either transcoding all of your video projects content into individual resolutions (ouch!) or using a solution to have a server do it for you (ahhh!). Make your product handle 360º video easily!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Christian Claus&lt;/strong&gt; - Product Manager, Holobuilder (christian@holobuilder.com)&lt;/p&gt;

&lt;h2 id=&quot;better-360-image-navigation-online&quot;&gt;&lt;strong&gt;Better 360º Image Navigation Online&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://lists.theta360.guide/uploads/default/original/1X/4e114047c46dea0f822dea01fb8504d69e4e45f3.png&quot; width=&quot;170&quot; height=&quot;177&quot; /&gt;
Christian will walk us through some of the challenges and issues that arise when building a 360º platform that lets users navigate through photospheres. How do you keep from going around in circles? Or worse, getting bored? Christian will touch on good storytelling and the implication for business applications based on his experience at Holobuilder, where he focuses on 360º construction content.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Eddie Codel&lt;/strong&gt; - Founder, Eddie.com/Flying Robot International Film Festival&lt;/p&gt;

&lt;h2 id=&quot;ricoh-theta-and-drones&quot;&gt;&lt;strong&gt;RICOH THETA and Drones!&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://lists.theta360.guide/uploads/default/original/1X/d3c9c547e5eef3a6e83f5d739b8e84879008bd4d.png&quot; width=&quot;170&quot; height=&quot;170&quot; /&gt;
Eddie will give us a “bird’s eye view” of video production using drones, including cutting-edge issues around mounting, stabilization, and avoiding curious birds. Eddie will also tell us about the Aerial Imaging Education Day he’s hosting in October and the Flying Robot International Film Festival and why THETA users in particular should participate.&lt;/p&gt;

&lt;p&gt;Food and drinks will be provided by RICOH THETA. See you all there!&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Sep 2016 00:00:00 +0000</pubDate>
        <link>http://theta360.guide/blog/api/2016/09/14/september-meetup.html</link>
        <guid isPermaLink="true">http://theta360.guide/blog/api/2016/09/14/september-meetup.html</guid>
        
        
        <category>API</category>
        
      </item>
    
  </channel>
</rss>
